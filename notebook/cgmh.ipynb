{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base='https://www.cgmh.org.tw/tw/Systems/RecruitInfo/'\n",
    "url_work_table='3'\n",
    "url=url_base+url_work_table\n",
    "g=requests.get(url)\n",
    "soup=BeautifulSoup(g.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages=soup.find_all('ul' ,class_=\"layout__pagination ul-reset\")[0]\n",
    "def get_pages(pages):\n",
    "  counter=0\n",
    "  for i, item in enumerate(pages):\n",
    "      if item.find('a') :\n",
    "        s = item.find('a')\n",
    "        counter += 1\n",
    "        try:\n",
    "          #print(s.get(\"href\") ,s.string)\n",
    "          if s.get(\"href\") == \"javascript:void(0)\":\n",
    "            counter -= 1\n",
    "        except:\n",
    "          counter -= 1\n",
    "          #print(item,'error')\n",
    "      \n",
    "  return counter\n",
    "get_pages(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = soup.find('div',class_=\"bg-grey pd100\").find_all('ul')[-2].find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_work_dead_line():\n",
    "    work_detail_web = soup.find('article').get_text().replace(\"\\xa0\",\"\").replace('\\n',\"\").replace(\"\\u3000\",\"\")\n",
    "    dead_line = work_detail_web.rsplit(\"報名期限\")[1].split(\"截止\")[0].replace(\"：\",\"\")\n",
    "    return dead_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_table=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_work_table(soup,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, item in enumerate(tables):\n",
    "    if item.find('a'): #過濾掉被刪除的文章\n",
    "        s = item.find('a')\n",
    "        work_detail_link = url_base+'/'+s.get('href').split('/')[-1]\n",
    "        title = item.find_all('div')[1].string\n",
    "        origantion = first_td.find_next_siblings('td')[0].string\n",
    "        dead_line = first_td.find_next_siblings('td')[2].string\n",
    "        print('#{}召聘職稱: {} 召聘單位: {}\\n 期限: {}\\n 連結：{}'.format(i+1, title, origantion, dead_line, work_detail_link ))\n",
    "        work_table.append([i-2, title, origantion, dead_line, work_detail_link ])\n",
    "\n",
    "work_table=pd.DataFrame(work_table, columns=['no','召聘職稱','召聘單位','期限' ,'連結'])\n",
    "\n",
    "print(work_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hospwork",
   "language": "python",
   "name": "hospwork"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
